{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(np.float)\n",
    "y_train = y_train.astype(np.float)\n",
    "x_train = x_train/np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of x_train: float64, dtype of y_train: float64\n",
      "Max of x_train: 1.0, Min of x_train: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"dtype of x_train: {0}, dtype of y_train: {1}\".format(x_train.dtype, y_train.dtype))\n",
    "print(\"Max of x_train: {0}, Min of x_train: {1}\".format(np.max(x_train), np.min(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first four images of x_train and their own labels are in the following:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAEYCAYAAAA6b7/5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZiU8UJqZlfBAaWZW4v8Damyp9PEULlAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b8c8be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The first four images of x_train and their own labels are in the following:\")\n",
    "f, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2)\n",
    "ax1.imshow(x_train[0], cmap='Greys',  interpolation='nearest')\n",
    "ax1.set_title('image label is {}'.format(y_train[0]))\n",
    "ax2.imshow(x_train[1], cmap='Greys',  interpolation='nearest')\n",
    "ax2.set_title('image label is {}'.format(y_train[1]))\n",
    "ax3.imshow(x_train[2], cmap='Greys',  interpolation='nearest')\n",
    "ax3.set_title('image label is {}'.format(y_train[2]))\n",
    "ax4.imshow(x_train[3], cmap='Greys',  interpolation='nearest')\n",
    "ax4.set_title('image label is {}'.format(y_train[3]))\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Discriminator(input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), input_shape=input_shape,\n",
    "              padding='valid', activation='relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid',\n",
    "              activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid',\n",
    "              activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid',\n",
    "              activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 99,201\n",
      "Trainable params: 99,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D = Discriminator((28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Generator(input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(7*7*64, input_shape=input_shape))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((7, 7, 64)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(filters=32, kernel_size=(3,3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(filters=16, kernel_size=(3,3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2DTranspose(filters=8, kernel_size=(3,3), padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(filters=1, kernel_size=(3,3), padding='same'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 8)         1160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         73        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 353,825\n",
      "Trainable params: 347,441\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G = Generator((100,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model(D):\n",
    "    optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "    DM = D\n",
    "    for l in DM.layers:\n",
    "        l.trainable = True\n",
    "    DM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    DM.summary()\n",
    "    return DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 99,201\n",
      "Trainable params: 99,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DM = discriminator_model(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adversarial_model(G, D):\n",
    "    optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "    AM = Sequential()\n",
    "    AM.add(G)\n",
    "    #D.trainable = False\n",
    "    for l in D.layers:\n",
    "        l.trainable = False\n",
    "    AM.add(D)\n",
    "    AM.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    AM.summary()\n",
    "    return AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_3 (Sequential)    (None, 28, 28, 1)         353825    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 99201     \n",
      "=================================================================\n",
      "Total params: 453,026\n",
      "Trainable params: 347,441\n",
      "Non-trainable params: 105,585\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AM = adversarial_model(G, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_steps=2000, batch_size=256, save_interval=0):\n",
    "    G = Generator((100,))\n",
    "    D = Discriminator((28,28,1))\n",
    "    discriminator =  discriminator_model(D)\n",
    "    adversarial = adversarial_model(G, D)\n",
    "    noise_input = None\n",
    "    if save_interval>0:\n",
    "        noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        \n",
    "    for i in range(train_steps):\n",
    "        images_train = x_train[np.random.randint(0, x_train.shape[0], size=batch_size), :, :, :]\n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "        images_fake = G.predict(noise)\n",
    "        x = np.concatenate((images_train, images_fake))\n",
    "        y = np.ones([2*batch_size, 1])\n",
    "        y[batch_size:, :] = 0\n",
    "        d_loss = discriminator.train_on_batch(x, y)\n",
    "\n",
    "        y = np.ones([batch_size, 1])\n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "        a_loss = adversarial.train_on_batch(noise, y)\n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "        print(log_mesg)\n",
    "        if save_interval>0:\n",
    "            if (i+1)%save_interval==0:\n",
    "                plot_images(save2file=True, samples=noise_input.shape[0], noise=noise_input, step=(i+1), G=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(save2file=False, fake=True, samples=16, noise=None, step=0, G=Generator):\n",
    "    filename = 'mnist.png'\n",
    "    if fake:\n",
    "        if noise is None:\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "        else:\n",
    "            filename = \"mnist_%d.png\" % step\n",
    "        images = G.predict(noise)\n",
    "    else:\n",
    "        i = np.random.randint(0, x_train.shape[0], samples)\n",
    "        images = x_train[i, :, :, :]\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(images.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        image = images[i, :, :]\n",
    "        image = np.reshape(image, [28, 28])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if save2file:\n",
    "        plt.savefig(filename)\n",
    "        plt.close('all')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 28, 28, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 28, 28, 8)         1160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 28, 28, 1)         73        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 353,825\n",
      "Trainable params: 347,441\n",
      "Non-trainable params: 6,384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 2049      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 99,201\n",
      "Trainable params: 99,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 2049      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 99,201\n",
      "Trainable params: 99,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_9 (Sequential)    (None, 28, 28, 1)         353825    \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 1)                 99201     \n",
      "=================================================================\n",
      "Total params: 453,026\n",
      "Trainable params: 347,441\n",
      "Non-trainable params: 105,585\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-93fd337a0d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-0fde963f9950>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_steps, batch_size, save_interval)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimages_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimages_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
